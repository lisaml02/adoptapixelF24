---
title: "image_processing"
output: html_document
date: "2024-10-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r loading packages}
library(tidyverse)
library(dplyr)
```

```{r loading in merged data}
# write_csv(merged_data_sf, "merged_data.csv")
library(data.table)
merged_data <- fread("merged_data.csv")


```

```{r}
# Adjust process_image to save each image locally once downloaded
process_image <- function(url) {
  local_file <- paste0("cached_images/", basename(url))
  
  # Check if the image is already cached
  if (!file.exists(local_file)) {
    tryCatch({
      download.file(url, local_file, mode = "wb")
    }, error = function(e) {
      return(data.frame(Red_mean = NA, Red_std = NA, Green_mean = NA, Green_std = NA, Blue_mean = NA, Blue_std = NA))
    })
  }
  
  # Process the image from local cache
  img <- load.image(local_file)  # imager's load.image
  
  # Split into RGB channels and calculate statistics
  r_channel <- as.numeric(img[,,1,1]) # Red channel
  g_channel <- as.numeric(img[,,1,2]) # Green channel
  b_channel <- as.numeric(img[,,1,3]) # Blue channel
  
  stats <- data.frame(
    Red_mean = mean(r_channel, na.rm = TRUE),
    Red_std = sd(r_channel, na.rm = TRUE),
    Green_mean = mean(g_channel, na.rm = TRUE),
    Green_std = sd(g_channel, na.rm = TRUE),
    Blue_mean = mean(b_channel, na.rm = TRUE),
    Blue_std = sd(b_channel, na.rm = TRUE)
  )
  return(stats)
}

```

```{r}
# Load required libraries
library(imager)
library(magick)
library(dplyr)
library(parallel)

# Ensure a folder exists for cached images
if (!dir.exists("cached_images")) {
  dir.create("cached_images")
}

# Function to download and process an image with caching and URL validation
process_image <- function(url) {
  if (!grepl("^https?://", url)) {
    return(data.frame(Red_mean = NA, Red_std = NA, Green_mean = NA, Green_std = NA, Blue_mean = NA, Blue_std = NA))
  }
  
  local_file <- paste0("cached_images/", basename(url))
  
  if (!file.exists(local_file)) {
    tryCatch({
      download.file(url, local_file, mode = "wb")
    }, error = function(e) {
      return(data.frame(Red_mean = NA, Red_std = NA, Green_mean = NA, Green_std = NA, Blue_mean = NA, Blue_std = NA))
    })
  }
  
  if (!file.exists(local_file)) {
    return(data.frame(Red_mean = NA, Red_std = NA, Green_mean = NA, Green_std = NA, Blue_mean = NA, Blue_std = NA))
  }
  
  img <- load.image(local_file)
  
  r_channel <- as.numeric(img[,,1,1])
  g_channel <- as.numeric(img[,,1,2])
  b_channel <- as.numeric(img[,,1,3])
  
  stats <- data.frame(
    Red_mean = mean(r_channel, na.rm = TRUE),
    Red_std = sd(r_channel, na.rm = TRUE),
    Green_mean = mean(g_channel, na.rm = TRUE),
    Green_std = sd(g_channel, na.rm = TRUE),
    Blue_mean = mean(b_channel, na.rm = TRUE),
    Blue_std = sd(b_channel, na.rm = TRUE)
  )
  return(stats)
}

# Function to process all directional photos for each observation
process_all_photos <- function(row) {
  urls <- row[c("north_photo_url", "south_photo_url", "west_photo_url", 
                "east_photo_url", "downward_photo_url", "upward_photo_url")]
  
  all_stats <- data.frame()
  
  for (photo_direction in names(urls)) {
    if (!is.na(urls[[photo_direction]])) {
      stats <- process_image(urls[[photo_direction]])
      stats <- cbind(photo_direction = photo_direction, stats)
      all_stats <- bind_rows(all_stats, stats)
    }
  }
  
  return(all_stats)
}

# Define the batch size and initialize final results
batch_size <- 100
final_results <- data.frame()

# Detect the number of available cores
num_cores <- detectCores() - 1  # Use one less than the maximum number of cores

# Convert merged_data_sf to dataframe if necessary
merged_data_df <- as.data.frame(merged_data)

# Batch processing loop with parallelization
for (i in seq(1, nrow(merged_data_df), by = batch_size)) {
  batch <- merged_data_df[i:min(i + batch_size - 1, nrow(merged_data_df)), ]
  
  # Use mclapply to process each row in parallel
  batch_results <- mclapply(1:nrow(batch), function(j) process_all_photos(batch[j, ]), mc.cores = num_cores)
  
  # Combine the results of the batch
  batch_combined <- do.call(rbind, batch_results)
  
  # Append batch results to final_results
  final_results <- rbind(final_results, batch_combined)
  
  # Save partial results and free memory
  saveRDS(final_results, "final_results_partial.rds")
  rm(batch, batch_results, batch_combined)
  gc()
  
  # Print progress
  print(paste("Processed batch", i, "to", min(i + batch_size - 1, nrow(merged_data_df))))
}

# Save the full final results
saveRDS(final_results, "final_results.rds")

```
